<!DOCTYPE html>
<html lang="en">

  <head>
    <link rel="icon" href="assets/images/png-clipart-gear-brain-human-head-icon-brain-gear-material-png-material-people-removebg-preview (1).png">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@100;200;300;400;500;600;700;800;900&display=swap" rel="stylesheet">

    <title>CAMI Symposium</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Additional CSS Files -->
    <link rel="stylesheet" href="assets/css/fontawesome.css">
    <link rel="stylesheet" href="assets/css/templatemo-space-dynamic.css">
    <link rel="stylesheet" href="assets/css/animated.css">
    <link rel="stylesheet" href="assets/css/owl.css">
<!--
    
TemplateMo 562 Space Dynamic

https://templatemo.com/tm-562-space-dynamic

-->
  </head>

<body>

  <!-- ***** Preloader Start ***** -->
  <div id="js-preloader" class="js-preloader">
    <div class="preloader-inner">
      <span class="dot"></span>
      <div class="dots">
        <span></span>
        <span></span>
        <span></span>
      </div>
    </div>
  </div>
  <!-- ***** Preloader End ***** -->

  <!-- ***** Header Area Start ***** -->
  <header class="header-area header-sticky wow slideInDown" data-wow-duration="0.75s" data-wow-delay="0s">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <nav class="main-nav">
            <!-- ***** Logo Start ***** -->
            <a href="index.html" class="logo">
              <img width="150px" height="60px" src="assets/images/logo_cami.svg"/>

            </a>
            <!-- ***** Logo End ***** -->
            <!-- ***** Menu Start ***** -->
            <ul class="nav">
              <li class="scroll-to-section"><a href="#top" class="active">Accueil</a></li>
              <li class="scroll-to-section"><a href="#about">À Propos</a></li>
              <li class="scroll-to-section"><a href="#services">Panel</a></li>
              <li class="scroll-to-section"><a href="#portfolio">Résumé</a></li>
              <li class="scroll-to-section"><a href="#poster">Posters</a></li> 
              <li class="scroll-to-section"><a href="#blog">Programme</a></li> 
              <li><a href="https://cami-symposium.github.io/index.html">EN</a></li> 
              <li class="scroll-to-section"><div class="main-red-button"><a href="#contact">Labs</a></div></li> 
              

            </ul>        
            <a class='menu-trigger'>
                <span>Menu</span>
            </a>
            <!-- ***** Menu End ***** -->
          </nav>
        </div>
      </div>
    </div>
  </header>
  <!-- ***** Header Area End ***** -->

  <div class="main-banner wow fadeIn" id="top" data-wow-duration="1s" data-wow-delay="0.5s" >
    <div class="container">
      <div class="row">
        <div class="col-lg-12">
          <div class="row">
            <div class="col-lg-6 align-self-center">
              <div class="left-content header-text wow fadeInLeft" data-wow-duration="1s" data-wow-delay="1s">
                <h6>Deuxième édition</h6>
                <h2>CAMI <em>Symposium</em> 
                  
                <p>LIV4D, MAGNU et VISIONIC se retrouvent pour la prochaine édition du mini-symposium, désormais le Symposium <span>Computer Analysis and Medical Imaging</span> ! Découvrez nos résumés étudiants, nos posters et le programme de l'édition 2024-2025 !</p>
                <form id="search" action="#" method="GET">
                  <fieldset>
                    <input type="address" name="address" class="email" placeholder="                 Date : Friday, 13 Dec 2024 @ 9h AM " center autocomplete="on" disabled>
                  </fieldset>
                  <fieldset>
                  </fieldset>
                </form>
              </div>
            </div>
            <div class="col-lg-6">
              <div class="right-image wow fadeInRight" data-wow-duration="1s" data-wow-delay="0.5s">
                <img src="assets/images/poster_v2.png" alt="team meeting">
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div id="about" class="our-services section">
    <div class="container">
      <div class="row">
        <div class="col-lg-6 align-self-center  wow fadeInLeft" data-wow-duration="1s" data-wow-delay="0.2s">
          <div class="left-image">
            <img src="assets/images/services-left-image.png" alt="">
          </div>
        </div>
        <div class="col-lg-6 wow fadeInRight" data-wow-duration="1s" data-wow-delay="0.2s">
          <div class="section-heading">
            <h2>Bienvenue à notre <em>Symposium</em> <span>CAMI</span> à Polytechnique Montréal</h2>
            <p>Le Symposium CAMI, créé par les étudiants et les laboratoires de Polytechnique Montréal sous la direction du <bold>Prof. Farida Cheriet, Prof. Lama Seoud et Prof. François Guibault</bold>, promeut les avancées dans l'information médicale et les applications de l'IA dans les soins de santé.<br> Cet événement dirigé par des étudiants réunit des chercheurs et des cliniciens pour explorer l'imagerie médicale, le diagnostic et le soutien à la décision pilotés par l'IA. À travers des discussions collaboratives et des présentations, le symposium favorise l'innovation et vise à rapprocher la technologie et la médecine pour améliorer les soins aux patients et la précision dans les soins de santé.</p>
          </div>
        </div>
       <div class="fadeIn section-heading wow" data-wow-duration="1s" data-wow-delay="0.2s" >
        <h2>Notre lieu <em>La Galerie Rolland</em></h2>
            <h5>6e étage, Bâtiment principal (B-600.16)</h5>
            <img src="assets/images/venue.png" alt="Lieu Polytechnique - Galerie Rolland">
       </div> 
      </div>
    </div>
  </div>

  <div id="services" class="about-us section">
    <div class="container">
      <div class="row">
        <div class="col-lg-4">
          <h1 style="color:white;">  Les panélistes </h1>
          <br> <br>
          <div class="left-image wow fadeIn" data-wow-duration="1s" data-wow-delay="0.2s">
            <img src="assets/images/about-left-image.png" alt="person graphic">
          </div>
        </div>
        <div class="col-lg-8 align-self-center">
          <div class="services">
            <div class="row">
              <div class="col-lg-6">
                <div class="item wow fadeIn" data-wow-duration="1s" data-wow-delay="0.5s">
                  <div class="icon">
                    <img src="assets/images/Rola-removebg-preview.png" alt="reporting">
                  </div>
                  <div class="right-text">
                    <h4>Rola Harmouche, PhD</h4>
                    <p>Chargé de recherche, CNRC</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-6">
                <div class="item wow fadeIn" data-wow-duration="1s" data-wow-delay="0.7s">
                  <div class="icon">
                    <img src="assets/images/benjamin-removebg-preview.png" alt="">
                  </div>
                  <div class="right-text">
                    <h4>Benjamin De Leener, PhD</h4>
                    <p>Codirecteur du laboratoire NeuroPoly, Polytechnique Montréal</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-6">
                <div class="item wow fadeIn" data-wow-duration="1s" data-wow-delay="0.9s">
                  <div class="icon">
                    <img src="assets/images/Michael-removebg-preview.png" alt="" >
                  </div>
                  <div class="right-text">
                    <h4>Michael Sauthier, MD, PhD</h4>
                    <p> Professeur associé et pédiatre, Université de Montréal</p>
                  </div>
                </div>
              </div>
              <div class="col-lg-6">
                <div class="item wow fadeIn" data-wow-duration="1s" data-wow-delay="1.1s">
                  <div class="icon">
                    <img src="assets/images/julia-keren (1).png" alt="">
                  </div>
                  <div class="right-text">
                    <h4>Julia Keren, B.Ed</h4>
                    <p>Co-Président de Kerenor Dental Studio, Responsable du Laboratoire Dentaire</p>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>


  <div id="portfolio" class="our-portfolio section">
    <div class="container">
      <div class="row">
        <div class="col-lg-6 offset-lg-3">
          <div class="section-heading  wow bounceIn" data-wow-duration="1s" data-wow-delay="0.2s">
            <h2>Résumés <span>Étudiants</span>
          </div>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-3 col-sm-6">
          <a class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.3s">
                <div class="hidden-content">
                    <h4>Zacharie Legault</h4>
                    <p>Représentation graphique des lésions rétiniennes pour un diagnostic interprétable de la rétinopathie diabétique</p>
                </div>
                <div class="showed-content">
                    <img src="assets/images/liv4d_logo_highres_transp.png" alt="">
                </div>
            </div>
        </a>
        
        <!-- Dialog Box -->
        <dialog class="dialogOne">
            <div class="dialog-content">
                <h3>RÉSUMÉ - Zacharie Legault </h3>
                <br>
                <h6>Représentation graphique des lésions rétiniennes pour un diagnostic interprétable de la rétinopathie diabétique</h6>
<p>La rétinopathie diabétique (RD) est l'une des principales causes de cécité parmi la population en âge de travailler dans le monde. Le diagnostic et la classification de la RD reposent sur l'identification de lésions rétiniennes caractéristiques par imagerie du fond d'œil. Malgré l'efficacité des techniques d'apprentissage profond dans la détection et la classification de la RD, ces méthodes manquent souvent d'interprétabilité. Ce travail introduit une nouvelle approche qui exploite une représentation graphique de la rétine, où chaque nœud correspond à une lésion, et un réseau neuronal graphique (GNN) est utilisé pour classer la RD. Notre méthode s'aligne sur les directives cliniques en utilisant des informations spécifiques à la lésion tout en conservant la capacité des modèles d'apprentissage profond. Nous segmentons d'abord les lésions de la RD à l'aide d'un réseau neuronal convolutionnel (CNN) pré-entraîné, puis construisons un graphique avec les lésions comme nœuds connectés à leurs k voisins les plus proches. Les caractéristiques de chaque nœud sont dérivées des régions spécifiques à la lésion dans l'image du fond d'œil. Le graphique de lésion obtenu est classé à l'aide d'un réseau d'attention graphique (GAT) pour faire la prédiction du grade DR. Notre méthode a été évaluée sur plusieurs ensembles de données publiques, atteignant des performances comparables aux techniques de pointe basées sur le kappa de Cohen pondéré quadratique et d'autres mesures. Cette approche basée sur des graphiques offre un équilibre entre la segmentation locale des lésions et la classification globale des images, améliorant potentiellement l'interprétabilité et la robustesse des applications cliniques.   </p>
                <button class="closeDialog">Close</button>
            </div>
        </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.4s">
              <div class="hidden-content">
                <h4>Samia Haidar</h4>
                <p>Harmoniques sphériques pour une modélisation complète de la forme des dents et une analyse de la variabilité</p>
</div>
              <div class="showed-content">
                <img src="assets/images/MAGNU_Francois_logo.png" alt="">
              </div>
            </div>
          </a>

          <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
            <h3>RÉSUMÉ - Samia Haidar </h3>
            <br>
            <h6>Harmoniques sphériques pour une modélisation complète de la forme des dents et une analyse de la variabilité</h6>
            <p>La complexité des formes des dents résulte d'une combinaison de diversité anatomique, d'adaptations fonctionnelles et de variations individuelles, même au sein d'une même position dentaire, ce qui se traduit par une large gamme de morphologies dentaires. Cette variabilité inhérente pose des défis pour représenter et analyser avec précision les formes dentaires, soulignant la nécessité de techniques de modélisation avancées pour capturer l'anatomie détaillée et la variabilité des dents. Les formes dentaires moyennes sont cruciales dans divers domaines, notamment le diagnostic, la planification du traitement, les objectifs éducatifs, les études sur l'évolution humaine et l'anthropologie médico-légale. Ce projet exploite un ensemble de données de formes de dents de divers patients pour modéliser et analyser la variabilité des dents à l'aide de représentations d'harmoniques sphériques. La méthodologie comprend la représentation de chaque dent avec des coefficients d'harmoniques sphériques, l'établissement de correspondances point à point et la création d'atlas pour chaque position de dent. La variabilité est analysée par analyse en composantes principales (ACP). Les résultats montrent une grande précision et un niveau de détail élevé dans les dents reconstruites en fonction des coefficients d'harmoniques sphériques. Les atlas capturent efficacement les caractéristiques critiques telles que les cuspides et les rainures, réduisent la subjectivité et révèlent une variabilité significative dans l'ensemble de données.
            </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.5s">
              <div class="hidden-content">
                <h4>Étienne Lescarbeault</h4>
                <p>TADA-SAE : Exploitation de la symétrie bilatérale dans les représentations de textures apprises pour l'imagerie thermique médicale</p>
                </div>
              <div class="showed-content">
                <img src="assets/images/VisionIC_carre_transp.png" alt="">
              </div>
            </div>
          </a>
          <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
            <h3>RÉSUMÉ - Étienne Lescarbeault</h3>
            <br>
            <h6>TADA-SAE : Exploitation de la symétrie bilatérale dans les représentations de texture apprises pour l'imagerie thermique médicale</h6>
            <p>La température de surface cutanée est un indicateur bien connu de la santé d'un patient. L'imagerie thermique est un outil efficace pour visualiser sa distribution d'intensités, ouvrant de nouvelles possibilités de diagnostic. De plus, la symétrie bilatérale des arrangements de température dans des parties opposées du corps peut être utilisée pour détecter des pathologies. En apprenant des représentations de texture et en comparant leurs asymétries, nous émettons l'hypothèse que les vecteurs latents de texture entre les thermographies de parties opposées du corps permettent de décrire efficacement les différences de température qui peuvent signaler une anomalie dans le domaine thermique. Notre modèle TADA-SAE (Texture Anomaly Detection using Swapping Autoencoder) est testé sur le jeu de données privé OrthoPOT pour les complications postopératoires suite à une arthroplastie totale des membres inférieurs et sur le jeu de données DMR-IR disponible au public pour la détection du cancer du sein. Un algorithme iForest formé sur des caractéristiques de symétrie et des données cliniques atteint 0,842 AUROC sur OrthoPOT et un AUROC compétitif de 0,988 sur DMR-IR tout en utilisant moins de paramètres que les méthodes traditionnelles. Notre méthode est la première à utiliser des caractéristiques de texture apprises et l'asymétrie pour la détection d'anomalies en imagerie thermique médicale, montrant des résultats prometteurs qui pourraient ouvrir la voie à d'autres tâches dans le domaine médical où la symétrie bilatérale peut être exploitée.
            </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.6s">
              <div class="hidden-content">
                <h4>Victor P., Lauriane, Valérie</h4>
                <p>Système d'évaluation automatique de la qualité du positionnement 
                  mammaire lors des examens mammographiques</p>
              </div>
              <div class="showed-content">
                <img src="assets/images/VisionIC_carre_transp.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
              <h3>RÉSUMÉ - Victor P., Lauriane, Valérie </h3>
              <br>
              <h6>Système d'évaluation automatique de la qualité du positionnement 
                mammaire lors des examens mammographiques</h6>
              <p>Le dépistage précoce du cancer du sein repose sur l'examen mammographique, dont la qualité dépend de nombreux facteurs, notamment le positionnement adéquat du sein dans le dispositif de compression. Une mauvaise qualité de positionnement peut entraîner des erreurs de  diagnostic ou des réexamens. Au Québec, près de 360 000 mammographies sont réalisées chaque année, avec des prévisions de croissance en  raison de la révision des lignes directrices de dépistage. Cependant, des études montrent que près de la moitié des examens ne respectent pas les critères de positionnement optimal, augmentant le risque de diagnostics erronés. Ce projet vise à développer un système d'évaluation automatique de la qualité du positionnement mammaire, en se basant sur 17 critères relatifs aux vues crânio-caudale (CC) et médio-latérale oblique (MLO). Diverses approches seront utilisées, incluant des techniques classiques de traitement d'image et des réseaux de neurones convolutionnels (CNN), ainsi que des méthodes d'apprentissage supervisé et semi-supervisé pour évaluer plusieurs critères simultanément. À ce jour, des méthodes classiques ont permis de délimiter les structures anatomiques du sein, et des réseaux de neurones sont en cours de développement pour évaluer quantitativement les critères de positionnement. Ce système pourrait améliorer la précision du dépistage et réduire les erreurs de diagnostic.
              </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
      </div>
      <br><br>
      <div class="row">
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.3s">
              <div class="hidden-content">
                <h4>Nazanin Abbasi Moghadam</h4>
                <p> Génération de prothèses 3D sur implants dentaires
                À l'aide d'un modèle de diffusion</p>
              </div>
              <div class="showed-content">
                <img src="assets/images/MAGNU_Francois_logo.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
            <h3>RÉSUMÉ - Nazanin Abbasi Moghadam </h3>
            <br>
            <h6>Génération de prothèses 3D sur implants dentaires
            À l'aide d'un modèle de diffusion</h6>
            <p>Cette étude présente une nouvelle approche pour la création de prothèses dentaires à l'aide d'un modèle de diffusion. La méthode utilise des nuages ​​de points 3D pour reconstruire des structures prothétiques complètes à partir de données dentaires incomplètes. En se concentrant sur les données fournies, le modèle remplit avec précision les zones manquantes tout en préservant les détails importants. De plus, il génère plusieurs conceptions réalistes, permettant aux cliniciens de choisir l'option la plus adaptée à chaque patient.
            </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.4s">
              <div class="hidden-content">
                <h4>Imane Chafi</h4>
                <p>Enregistrement multimodal pour la caractérisation interne non invasive des préparations dentaires</p>
                </div>
              <div class="showed-content">
                <img src="assets/images/MAGNU_Francois_logo.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
            <h3>RÉSUMÉ - Imane Chafi </h3>
            <br>
            <h6>Enregistrement multimodal pour la caractérisation interne non invasive des préparations dentaires</h6>
            <p>La visualisation interne des préparations dentaires représente un défi dans les procédures de mise en place de couronnes. Les scanners intrabuccaux, bien qu'innovants et peu invasifs, ne fournissent que des informations de surface, ce qui rend difficile l'évaluation des structures internes de la dent. Pour répondre à cette problématique, notre recherche propose l'utilisation combinée de scanners CBCT (cone beam computing tomography) et de scanners intrabuccaux dès la procédure de préparation. Grâce à l'enregistrement 3D entre ces deux types de données, nous pouvons visualiser les structures internes des préparations. Les résultats préliminaires montrent que cette technique permet une évaluation plus approfondie des préparations dentaires, offrant aux dentistes un outil pour améliorer la précision de leurs interventions. Cette recherche ouvre la voie à une automatisation partielle des procédures de préparation dentaire. Le développement de cette technique
            offre aux dentistes une méthode informatique qui combine à la fois
            la visualisation interne et externe des dents, présentant
            une nouvelle approche de l'évaluation des préparations dentaires.
            </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.5s">
              <div class="hidden-content">
                <h4>Gaspar Faure</h4>
            <p>Apprentissage métrique profond auto-supervisé pour la récupération de lésions prototypiques à zéro coup dans des images de lames entières de placenta </p>
            </div>
              <div class="showed-content">
                <img src="assets/images/VisionIC_carre_transp.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
            <h3>RÉSUMÉ - Gaspar Faure </h3>
            <br>
            <h6>Apprentissage métrique profond auto-supervisé pour la récupération de lésions prototypiques à zéro coup dans les images de lames entières de placenta</h6>
            <p>Les lésions placentaires peuvent prédire une éventuelle récidive lors de grossesses ultérieures et expliquer les résultats et les effets indésirables postnatals. Cependant, l'analyse des images de lames entières de placenta (WSI) n'est pas effectuée systématiquement en raison du niveau spécifique de compétences requis. Il n'existe pas d'ensemble de données publiques disponibles pour les WSI du placenta et les annotations précises et consensuelles sont très limitées. Dans ce contexte de faible disponibilité des données et compte tenu de la tâche presque impossible d'obtenir une annotation précise par des experts, nous proposons une nouvelle méthode basée sur l'apprentissage métrique profond (DML) pour une récupération efficace des lésions inflammatoires dans les WSI du placenta. Nous formons un encodeur d'images sans aucune étiquette, en utilisant uniquement des WSI normaux avec un cadre d'apprentissage auto-supervisé (SSL) inspiré de MoCo v2. Cet encodeur d'images est utilisé pour définir des vecteurs prototypes pour les lésions inflammatoires, en utilisant un nombre très limité de patchs pathologiques connus, extraits d'un seul placenta. Nous pouvons ensuite récupérer des lésions inflammatoires à partir de WSIs non observés en comparant les patchs avec le vecteur prototype dans l'espace métrique de l'encodeur d'images. La carte de similarité obtenue est ensuite affinée à l'aide d'une méthode de post-traitement simple pour prendre en compte la proximité spatiale des patchs. Nous avons évalué notre méthode sur un ensemble de données privées de 165 WSIs de placenta annotés ainsi que sur l'ensemble de données CAMELYON16 pour la récupération des métastases ganglionnaires.
            </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.6s">
                <div class="hidden-content">
                    <h4>Cyprien Arnold</h4>
                    <p>Super-résolution d’images thermiques d’enfants en soins intensifs pédiatriques</p>
                    </div>
              <div class="showed-content">
                <img src="assets/images/VisionIC_carre_transp.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
              <h3>RÉSUMÉ - Cyprien Arnold </h3>
              <br>
              <h6>Super-résolution d’images thermiques d’enfants en soins intensifs pédiatriques</h6>
              <p>Ce travail de recherche porte sur la super-résolution d’images thermiques. Il a été développé pour améliorer le monitorage des enfants en soins intensifs pédiatriques. En effet, l’utilisation de caméras thermiques permettraient d’orienter et de faciliter le travail du personnel médical vers les cas les plus sévères visant ainsi à améliorer l’organisation du travail du personnel soignant dont les effectifs sont très tendus. Les caméras thermiques ont de nombreuses applications dans le milieu médicale. Elles permettent une surveillance non-invasive (qui ne gène pas le patient)  tout en permettant l’accès à sa température ou à la position de ses membres sous une couverture. Cependant, le coût à l’achat d’une caméra thermique de bonne qualité, avec une grande résolution, demeure très élevé. Il existe des caméras thermiques bon marché mais avec une  résolution très dégradée. L’objectif de ce travail de recherche est de pouvoir exploiter les images thermiques en augmentant la qualité des images acquises avec des caméras thermiques de faible résolution. Ce processus d’augmentation de la qualité d’une image est appelé, super  résolution (SR). Cette tache de vision par ordinateur est une tache qui a été très étudié ces dernières années et dans ce mémoire nous présentons une nouvelle architecture de réseau de neurone avec des résultats très compétitifs. L’originalité de ce travail de recherche porte sur le fait d’utiliser l’image du spectre du visible dans le but d’améliorer la qualité de l’image thermique tout en assurant une robustesse de la méthode dans le cas où une modalité manquerait.
              </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
      </div>

      <br><br>
      <div class="row">
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.3s">
                <div class="hidden-content">
                    <h4>Doha Zrouki</h4>
                    <p>Classification automatique du glaucome à angle fermé à l'aide d'images du segment antérieur de l'œil</p>
                    </div>
              <div class="showed-content">
                <img src="assets/images/VisionIC_carre_transp.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
            <h3>RÉSUMÉ - Doha Zrouki </h3>
            <br>
            <h6>Classification automatique du glaucome à angle fermé à l'aide d'images du segment antérieur de l'œil</h6>
            <p>Le glaucome à angle fermé primaire (PACG) est l'une des principales causes de cécité dans le monde, particulièrement répandu parmi les populations vieillissantes et certains groupes ethniques. Une détection précoce est essentielle pour prévenir une perte de vision irréversible, mais les méthodes de diagnostic actuelles telles que la tomographie par cohérence optique (OCT), la gonioscopie et la tonométrie sont limitées par les coûts élevés, le besoin d'équipement spécialisé et l'inconfort du patient. Cette étude explore une alternative non invasive et rentable pour la détection du PACG à l'aide d'images oculaires externes obtenues à partir du test de Van Herick, qui évalue l'angle de la chambre antérieure sans nécessiter de contact visuel direct ou de dilatation de la pupille.
            </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.4s">
              <div class="hidden-content">
                <h4>Philippe Baumstimler</h4>
                <p>Détection d’anomalies dans les photographies du segment antérieur de l’œil par apprentissage profond non supervisé</p>
              </div>
              <div class="showed-content">
                <img src="assets/images/VisionIC_carre_transp.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
              <h3>RÉSUMÉ - Philippe Baumstimler </h3>
              <br>
              <h6>Détection d’anomalies dans les photographies du segment antérieur de l’œil par apprentissage profond non supervisé 
              </h6>
              <p>Le diagnostic des pathologies oculaires menant à la perte de vision constitue un enjeu économique et social majeur au Canada. En raison des contraintes liées au manque de personnel spécialisé, notamment dans les régions éloignées, et du manque de ressources financières, la téléophtalmologie  offre une solution prometteuse en combinant imagerie médicale et analyse à distance. Largement fondée sur l'imagerie du fond d’œil, qui bénéficie d'un riche corpus d'études scientifiques, elle nécessite cependant des équipements spécialisés et coûteux, freinant ainsi son déploiement à grande échelle. Face à ces limitations, l’imagerie du segment antérieur de l’œil se présente comme une alternative intéressante. Plus accessible et économique, elle permet l’identification de pathologies grâce à des photographies prises à l’aide d’une lampe à fente. Ce mémoire se concentre sur le développement d’une méthode de détection d’anomalies non supervisée pour les photographies de la conjonctive. En s’appuyant sur des approches par reconstruction, l’objectif est d'identifier toute structure anatomique sortant de la définition de la normalité apprise. À cet effet, nous avons d’abord constitué une base de données adaptée, puis développé SiamAAE, un modèle d'apprentissage profond innovant qui combine reconstruction et auto-distillation surmontant les biais liés à l’apprentissage de l’identité observés dans les modèles de la littérature, tout en conservant les performances en détection d’anomalies de ces dernières.
                Cette étude marque une première étape dans l'exploration des méthodes non supervisées de détection d'anomalies appliquée aux photographies du segment antérieur de l’œil. 
              </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.5s">
              <div class="hidden-content">
                <h4>Hugo Rodet</h4>
                <p>Diversité des formes corporelles dans les méthodes de génération de poses humaines et leurs données d'apprentissage </p>
                </div>
              <div class="showed-content">
                <img src="assets/images/VisionIC_carre_transp.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
            <h3>RÉSUMÉ - Hugo Rodet </h3>
            <br>
            <h6>Diversité des formes corporelles dans les méthodes de génération de poses humaines et leurs données d'apprentissage</h6>
            <p>La description du mouvement humain est essentielle à de nombreuses applications allant de la médecine à l'animation 3D. Cependant, tout le monde ne bouge pas de la même manière, et ce projet vise à mettre en évidence spécifiquement l'influence de la forme du corps sur les poses possibles. Nous étudions l'ensemble de données AMASS, lui-même un agrégat unifié de différents ensembles de données de capture de mouvement, nous permettant de tirer des conclusions plus générales. Grâce à une mesure d'auto-intersection, nous montrons que les poses effectuées par des individus à faible IMC ne sont pas adaptées aux formes corporelles à IMC élevé. En étendant ces résultats à plusieurs architectures de génération de poses habituelles qui représentent des éléments constitutifs des méthodes récentes, nous concluons que ne pas prendre en compte la forme du corps pendant la génération donne des poses inadaptées à une utilisation avec des modèles corporels à IMC élevé. Ces évaluations sont valables même en contrôlant la diversité des poses et le réalisme des méthodes évaluées. Une comparaison de la distribution des IMC dans AMASS et dans la population américaine révèle que les IMC élevés et faibles sont sous-représentés dans les données, ce qui suggère que ce problème provient non seulement des architectures elles-mêmes, mais aussi des données sur lesquelles elles ont été formées. Nous soulignons l'importance d'inclure des formes corporelles plus diverses lors de la collecte des données de mouvement et directement dans les architectures.
            </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>
        </div>
        <div class="col-lg-3 col-sm-6">
          <a  class="openDialog">
            <div class="item wow bounceInUp" data-wow-duration="1s" data-wow-delay="0.6s">
              <div class="hidden-content">
                <h4>Golriz Hosseinimanesh</h4>
                <p>Génération 3D de couronnes dentaires à l'aide de Transformers</p>
                </div>
              <div class="showed-content">
                <img src="assets/images/MAGNU_Francois_logo copy.png" alt="">
              </div>
            </div>
          </a>
           <!-- Dialog Box -->
        <dialog class="dialogOne">
          <div class="dialog-content">
              <h3>RÉSUMÉ - Golriz Hosseinimanesh </h3>
              <br>
              <h6>TBD</h6>
              <p>TBD
              </p>
              <button class="closeDialog">Close</button>
          </div>
      </dialog>

        </div>
        
      </div>
      <br><br><br><br><br>
      <div>
        <div id="poster" class="section-heading  wow bounceIn" data-wow-duration="1s" data-wow-delay="0.2s">
            <h2>Modèle d'affiche</h2>
        </div>
        <center>     
  
          <iframe src="https://drive.google.com/file/d/1YYyOhHKb6GiVMFEgNdITvDecyNg2jlWF/preview" width=100% height="480" allow="autoplay"></iframe>
          <br><br><br>
          <div class="main-red-button"><a href="https://docs.google.com/presentation/d/1YYyOhHKb6GiVMFEgNdITvDecyNg2jlWF/edit?usp=sharing&ouid=105631853127023396460&rtpof=true&sd=true">Téléchargez ici notre modèle d'affiche PPTX avec les exigences de taille !</a></div>
        </center>
      </div>
      
    </div>
  </div>

  <div id="blog" class="our-blog section">
    <div class="container">
      <div class="row">
        <div class="col-lg-6 wow fadeInDown" data-wow-duration="1s" data-wow-delay="0.25s">
          <div class="section-heading  wow bounceIn" data-wow-duration="1s" data-wow-delay="0.2s">

            <h2>Découvrez notre <span>Programme</span> de la journée</h2>
            <br>
            <br>
          </div>
        </div>
        <div class="col-lg-6 wow fadeInDown" data-wow-duration="1s" data-wow-delay="0.25s">
          <div class="top-dec">
          </div>
        </div>

        
      
      </div>
     
      <div class="row">
        <div class="col-lg-6 wow fadeInUp" data-wow-duration="1s" data-wow-delay="0.25s">
          <div class="left-image">
            <iframe src="https://drive.google.com/file/d/1KUHJcWrmPl345GG4NTr4zIlDfUDJU9tI/preview" width=100% height="750" ></iframe>
          </div>
        </div>
        <div class="col-lg-6 wow fadeInUp" data-wow-duration="1s" data-wow-delay="0.25s">
          <div class="right-list">
            <ul>
              <li>
                <div class="left-content align-self-center">
                    <span><i class="fa fa-calendar"></i> @ 9h AM</span>
                    <a href="#"><h4>Déclaration de bienvenue</h4></a>
                    <p>Comprend une présentation des laboratoires organisateurs et des laboratoires invités avec le professeur Hervé Lombaert.</p>
                    </div>
                    <div class="right-image">
                    <a href="#"><img src="assets/images/istockphoto-1181250359-612x612.jpg" alt=""></a>
                    </div>
              </li>
              <li>
                <div class="left-content align-self-center">
                    <span><i class="fa fa-calendar"></i> à 9h50 et à 15h10</span>
                    <a href="#"><h4>Présentations et posters</h4></a>
                    <p>Présentations courtes et longues des étudiants, consultez leurs résumés dans la section résumés</p>
                    </div>
                    <div class="right-image">
                    <a href="#"><img src="assets/images/1564119781518.jpeg" alt=""></a>
                    </div>
                    </li>
              <li>
                <div class="left-content align-self-center">
                    <span><i class="fa fa-calendar"></i> 06 mars 2021</span>
                    <a href="#"><h4>Table ronde</h4></a>
                    <p>Quatre intervenants invités - Rola Harmouche, Michael Saunthier, Benjamin De Leener et Julia Keren discutent de l'IA en médecine, avec une animation du Prof. Lama Seoud </p>
                    </div>
                    <div class="right-image">
                    <a href="#"><img src="assets/images/istockphoto-1382269943-612x612.jpg" alt=""></a>
                    </div>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div id="contact" class="contact-us section">
    <div class="container">
      <div class="row">
        <div class="col-lg-6 align-self-center wow fadeInLeft" data-wow-duration="0.5s" data-wow-delay="0.25s">
          <div class="section-heading">
            <h2>LIV4D, MAGNU ET VISIONIC </h2>
            <p>Le Symposium CAMI est une conférence clé pour l'imagerie médicale et l'IA, réunissant des chercheurs, des cliniciens et des experts du secteur pour explorer les innovations dans l'imagerie pilotée par l'IA. Il couvre des sujets tels que l'analyse d'images, le diagnostic et la planification chirurgicale, favorisant la collaboration pour améliorer la médecine de précision et améliorer les soins aux patients. </p>
            <div class="phone-info">
            <h4>Pour toute demande de renseignements, contactez-nous : <span><i class="fa fa-home"></i> <a href="#">M-3202</a></span></h4>
            </div>
          </div>
        </div>
        <div class="col-lg-6 wow fadeInRight" data-wow-duration="0.5s" data-wow-delay="0.25s">
          <img src="assets/images/labs.png" alt="">

        </div>
      </div>
    </div>
  </div>

  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-12 wow fadeIn" data-wow-duration="1s" data-wow-delay="0.25s">
          <p>© Copyright 2024 Imane Chafi @ CAMI Symposium. 
          
        </div>
      </div>
    </div>
  </footer>
  <!-- Scripts -->
  
  <script>
// Disable scroll when modal opens
function disableScroll() {
    const scrollPosition = window.pageYOffset || document.documentElement.scrollTop;
    // Store the scroll position
    document.body.style.position = 'fixed';
    document.body.style.top = `-${scrollPosition}px`;  // Prevent page from scrolling
    document.body.style.left = '0';
    document.body.style.width = '100%';
    document.body.style.height = '100%';
    document.body.style.overflow = 'hidden';  // Prevent scroll
}

// Enable scroll when modal closes
function enableScroll() {
    // Remove the styles that were applied to prevent scroll
    const scrollPosition = parseInt(document.body.style.top || '0') * -1;  // Get the previous scroll position
    document.body.style.position = '';
    document.body.style.top = '';
    document.body.style.left = '';
    document.body.style.width = '';
    document.body.style.height = '';
    document.body.style.overflow = '';

    // Scroll back to the previous position without jumping to the top
    window.scrollTo(0, scrollPosition);
}

// Get all the dialog elements and open buttons
const dialogElements = document.getElementsByClassName('dialogOne');
const openDialogButtons = document.getElementsByClassName('openDialog');

// Loop through each open button and set up event listeners
for (let i = 0; i < openDialogButtons.length; i++) {
    const openDialogButton = openDialogButtons[i];
    const dialogOne = dialogElements[i]; // Match dialog box with its open button

    const closeDialogButton = dialogOne.querySelector('.closeDialog'); // Get the close button for each dialog

    // When the open button is clicked, show the dialog and disable scrolling
    openDialogButton.addEventListener('click', function(event) {
        event.preventDefault(); // Prevent the default action of the link
        disableScroll(); // Prevent scrolling when dialog opens
        dialogOne.showModal(); // Open the dialog
    });

    // When the close button is clicked, close the dialog and enable scrolling
    closeDialogButton.addEventListener('click', function() {
        dialogOne.close(); // Close the dialog
        enableScroll(); // Allow scrolling again
    });
}
</script>

  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/js/owl-carousel.js"></script>
  <script src="assets/js/animation.js"></script>
  <script src="assets/js/imagesloaded.js"></script>
  <script src="assets/js/templatemo-custom.js"></script>
 

</body>
</html>
